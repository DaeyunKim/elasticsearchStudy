# Analysis



index  mapping 



logstash 로 데이터 업로드 



```json
PUT /bigginsight
{
  "settings": {
    "index": {
      "number_of_replicas": "1",
      "number_of_shards": "5"
    }
  },
  "mappings": {
    "usageReport": {
      "properties": {
        "accessPointId": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "application": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "band": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "bandwidth": {
          "type": "double"
        },
        "category": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "customer": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "department": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "downloadCurrent": {
          "type": "double"
        },
        "downloadTotal": {
          "type": "integer"
        },
        "inactiveMs": {
          "type": "integer"
        },
        "location": {
          "type": "geo_point"
        },
        "mac": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "networkId": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        },
        "signalStrength": {
          "type": "integer"
        },
        "time": {
          "type": "date",
          "format": "strict_date_optional_time||epoch_millis"
        },
        "uploadCurrent": {
          "type": "double"
        },
        "uploadTotal": {
          "type": "integer"
        },
        "usage": {
          "type": "double"
        },
        "username": {
          "type": "keyword",
          "fields": {
            "analyzed": {
              "type": "text"
            }
          }
        }
      }
    }
  }
}
```



## 집계 기초

분석은 검색과 달리 더 큰 범위를 다룬다.

```json
POST /<index_name>/<type_name>/_search
{
    "query": {...쿼리}
}
```



Aggregations 또는 aggs 요소는 데이터를 집계하는데 사용.



```json
POST /<index_name>/<type_name>/_search
{
    "aggs":{...집계 타입...},
    "query":{...쿼리 타입...},
    "size": 0
}
```



* Bucket 집계
* Metric 집계
* Matrix 집계
* Pipeline 집계



### Bucket 집계

버킷 키로 식별되는 여러 버킷에 쿼리 컨텍스트에서 정의된 문제의 데이터를 분할.

Bucket 집계는 컨테스트에 있는 각 도큐먼트가 어떤 버킷에 속해 있는지 결정해 평가

Bucket 집계는 집계쿼리 쿼리에서 최상단 혹은 가장 바깥에 위치 할 수 있다.

다른 Bucket집계 내부에 중첩해 사용할 수 도 있음.

### Metric 집계

필드에서 숫자 타입으로 동작, 주어진 컨텍스트에서 숫자 필드의 집계값을 계산하는데 사용

Matric 집계 또한 다른 집계 타입과 중첩해서 사용이 가능하다.



### Metrix 집계

여러 필드에서 동작하고 쿼리 컨텍스트 내의 모든 도큐먼트에 걸쳐 메트릭을 계산한다.

Matrix 집계는 Bucket 집계에 중첩해사용할수는 있지만, Bucket 집계는 Matrix내부에 중첩 될 수 없다.



### Pipeline집계

다른 타입의 집계 결과를 다시 집계할 수 있는 상위 레벨의 집계.

상위레벨에서 제공하는 다양한 타입의 집계를 기반으로 함.



##Metric 집계

숫자 데이터를 다룸

* 합계, 평균, 최소, 최대 집계
* 통계 및 확장 통계 집계
* 카디널리티 집계



### 합계, 평균, 최소, 최대 집계

테이블 또는 컨텍스트에서 모든 레코드를 검토후에 해당 필드 값을 더한다.

```json
GET bigginsight/_search
{
  "aggs":{
    "download_sum":{
      "sum":{
        "field": "downloadTotal"
      }
    }
  },
  "size": 0
}
```

"Size":0 을 하지 않으면 원본의 데이터의 내용이 출력되고 이후 aggs의 결과 값이 출력된다.

결과 값 : "aggregation" 필드 아래에 download_sum이라고 쿼리에서 정해준 필드의 이름으로 value 값 이 나온다.

```json
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 242835,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "download_sum" : {
      "value" : 2.1974387E9
    }
  }
}
```



###Average 집계

```json
GET bigginsight/_search
{
  "aggs":{
    "download_average":{
      "avg":{
        "field": "downloadTotal"
      }
    }
  },
  "size":0
}
```

결과 : 

```json
 },
  "aggregations" : {
    "download_average" : {
      "value" : 9049.102065188297
    }
  }
}
```

이 이외에 **max, min** 등이 추가로 지원한다.



### 통계 및 확장 통계 집계



**stats**

단일 요청에서 공통 통계값을 계산 가능, stat 집계는 **합계, 평균, 최소, 최대** 를 계산한다.

```json
GET bigginsight/_search
{
  "aggs":{
    "download_stats":{
      "stats":{
        "field": "downloadTotal"
      }
    }
  },
  "size":0
}
```

결과 값 : 

```json
{  
  "took" : 26,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 242835,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "download_average" : {
      "count" : 242835,
      "min" : 0.0,
      "max" : 241213.0,
      "avg" : 9049.102065188297,
      "sum" : 2.1974387E9
    }
  }
}
```



**extended_stats**

Stats 보다 더 추가적으로 제곱, 분산, 표준편차, 표준 편차 구간을 반환

```json
GET bigginsight/_search
{
  "aggs":{
    "download_average":{
      "extended_stats":{
        "field": "downloadTotal"
      }
    }
  },
  "size":0
}
```

결과 값

```json
  },
  "aggregations" : {
    "download_average" : {
      "count" : 242835,
      "min" : 0.0,
      "max" : 241213.0,
      "avg" : 9049.102065188297,
      "sum" : 2.1974387E9,
      "sum_of_squares" : 1.33545882701698E14,
      "variance" : 4.680587049782911E8,
      "std_deviation" : 21634.664429528162,
      "std_deviation_bounds" : {
        "upper" : 52318.43092424462,
        "lower" : -34220.22679386803
      }
    }
  }
```



**cardinality 집계**

특정 요소의 개수를 찾는데 유용

특정필드의 카디널리티 또는 고유한 값의 개수를 찾는 일은 매우 일반적인 요구사항이다.

예를 들면, 특정 날짜 또는 주간, 월간 방문자를 알고 싶을때

```json
GET bigginsight/_search
{
  "aggs":{
    "unique_visitors":{
      "cardinality":{
        "field": "downloadTotal"
      }
    }
  },
  "size":0
}
```

결과 값 : 

```json
  },
  "aggregations" : {
    "unique_visitors" : {
      "value" : 37248
    }
  }
```





## Bucket 집계

데이터를 더 작은 부분으로 세분화, Bucket 집계의 각 타입은 여러 segment 혹은 버킷으로 데이터를 분할.

bucketing은 공통 기준에 따라 도큐먼트를 그룹화 하는 것을 말한다.

* 문자열 데이터 버킷팅
* 숫자 데이터 버킷팅
* 필터 데이터 집계
* 중첩 집계
* 맞춤형 조건 버킷팅
* 날짜 또는 시간 데이터 버킷팅
* 지리 공간 데이터 버킷팅



### 문자열 데이터 버킷팅

키워드 타입 필드를 기반으로 데이터 또는 세그먼트를 버킷에 보관이 가능하다.

**Term 집계**

```json
GET bigginsight/usageReport/_search
{
  "aggs":{
    "byCategory":{
      "terms":{
        "field":"category"
      }
    }
  },
  "size":0
}
```

결과 값 : 

```json
{
  "took" : 18,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 242835,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "byCategory" : {
      "doc_count_error_upper_bound" : 0,
      "sum_other_doc_count" : 0,
      "buckets" : [
        {
          "key" : "Chat",
          "doc_count" : 52277
        },
        {
          "key" : "File Sharing",
          "doc_count" : 46912
        },
        {
          "key" : "Other HTTP",
          "doc_count" : 38535
        },
        {
          "key" : "News",
          "doc_count" : 25784
        },
        {
          "key" : "Email",
          "doc_count" : 21003
        },
        {
          "key" : "Gaming",
          "doc_count" : 19578
        },
        {
          "key" : "Jobs",
          "doc_count" : 19429
        },
        {
          "key" : "Blogging",
          "doc_count" : 19317
        }
      ]
    }
  }
}
```

doc_counter_error_upper_bound는 집계 수행시 발생한 오류 개수를 나타낸다.

각 샤드가 모든 버킷 키에 대한 데이터를 보내면, 네트워크를 통해 전송되는 데이터가 너무 많아 질 수 있다.

일래스틱 서치에서는 상위 N개 항목에 대한 집계가 요청된 경우, 네트워크를 통해 N개의 버킷만 전송하게되는데, size 매개변수로 결정할 수 있다.



Sum_other_doc_count 는 반환된 버킷에 포함되지 않는 총 도큐먼트 개수이다.





field를 application으로 지정한다면 

```json
GET bigginsight/usageReport/_search
{
  "aggs":{
    "byApplication":{
      "terms":{
        "field":"application"
      }
    }
  },
  "size":0
}
```

결과값 : 

기본적으로 terms 집계가 기본적으로 10개 버킷만 반환하기 때문에 이외의 것은 sum_other_doc_count에 표기

가장 많은 도큐먼트가 있는 버킷이 내림차순으로 정렬



cardinality를 사용하여 application의 개수를 보아하니, 30개가 있는데 이들중 10개만 상위에 표기가 된 것 같다.

나머지 20개의 doc들의 합이 128989가 되는 것이다.

```json
{
  "took" : 0,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : 242835,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "byApplication" : {
      "doc_count_error_upper_bound" : 6303,
      "sum_other_doc_count" : 128989,
      "buckets" : [
        {
          "key" : "Skype",
          "doc_count" : 26115
        },
        {
          "key" : "Dropbox",
          "doc_count" : 22671
        },
        {
          "key" : "www.microsoft.com",
          "doc_count" : 9709
        },
        {
          "key" : "Microsoft Skydrive",
          "doc_count" : 9662
        },
        {
          "key" : "netflix.com",
          "doc_count" : 9600
        },
        {
          "key" : "Gmail",
          "doc_count" : 8123
        },
        {
          "key" : "Windows Filesharing",
          "doc_count" : 8033
        },
        {
          "key" : "GTalk",
          "doc_count" : 6730
        },
        {
          "key" : "Candy Crush",
          "doc_count" : 6661
        },
        {
          "key" : "Viber",
          "doc_count" : 6542
        }
      ]
    }
  }
}

```

기본값인 10개이외에 더 많은 버킷을 얻으려면, term 집계에서 size 매개 변수를 사용한다.

```json
GET bigginsight/usageReport/_search
{
  "aggs":{
    "byApplication":{
      "terms":{
        "field":"application",
        "size":15
      }
    }
  },
  "size":0
}
```



### 숫자 데이터 버킷팅

데이터를 다른 간격의 범위로 분할이 가능, 예를 들면, 데이터를 연령, 직원수 등으로 분류할때

* Histogram 집계
* Range 집계

**Histogram 집계**

```json
POST /bigginsight/_search
{
  "aggs": {
    "by_usage":{
      "histogram": {
        "field": "usage",
        "interval": 10000
      }
    }
  },
  "size":0
}
```

interval의 간격으로 집계를 출력한다.

```json
"aggregations" : {
    "by_usage" : {
      "buckets" : [
        {
          "key" : 0.0,
          "doc_count" : 207708
        },
        {
          "key" : 10000.0,
          "doc_count" : 5732
        },
        {
          "key" : 20000.0,
          "doc_count" : 5766
        },
        {
          "key" : 30000.0,
          "doc_count" : 5178
        },
```





**Range 집계**

range를 별도로 지정 할 수 있다.

Ranges 배열에 범위를 지정한다. from (value) 에서 to (value) 이하 까지

```json
POST /bigginsight/_search
{
  "aggs": {
    "by_usage":{
      "range": {
        "field": "usage",
        "ranges": [
          { "to": 1024},
          { "from": 1024, "to":102400},
          { "from": 102400}
        ]
      }
    }
  },
  "size":0
}
```

Range 안에 "key":" manual_key" 를 지정하여 라벨을 지정할 수 있다.

결과 값 : 

```json
},
  "aggregations" : {
    "by_usage" : {
      "buckets" : [
        {
          "key" : "*-1024.0",
          "to" : 1024.0,
          "doc_count" : 31324
        },
        {
          "key" : "1024.0-102400.0",
          "from" : 1024.0,
          "to" : 102400.0,
          "doc_count" : 207498
        },
        {
          "key" : "102400.0-*",
          "from" : 102400.0,
          "doc_count" : 4013
        }
      ]
    }
  }
```





### 필터 데이터 집계

